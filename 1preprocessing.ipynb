{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/alfinmaulani/skripsi/blob/master/1preprocessing.ipynb",
      "authorship_tag": "ABX9TyMLAlscXQsPivgc+Uy7jYua",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfinmaulani/skripsi/blob/master/1preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci3dfx-9C_ji",
        "outputId": "018043b8-674a-4077-dfb3-b2cf0a140b3a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14MGN2ehbbJS"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv1tydmpblTq"
      },
      "source": [
        "!kill process_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2hacXvT3mX8"
      },
      "source": [
        "url0='https://raw.githubusercontent.com/alfinmaulani/skripsi/master/dataISEAR.csv'\n",
        "df = pd.read_csv(url0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecmoGKcODIAZ",
        "outputId": "38c8d9fe-9609-4993-af13-02f4825bc6d0"
      },
      "source": [
        "df.emosi.value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "joy        1092\n",
              "sadness    1082\n",
              "anger      1079\n",
              "fear       1076\n",
              "shame      1071\n",
              "disgust    1066\n",
              "guilt      1050\n",
              "Name: emosi, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5APBEuD1Hw5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc6d205-62e2-4125-d6b7-e480f4e6d241"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78BBpIJ2Rlrj"
      },
      "source": [
        "dfblog = pd.read_csv('/content/drive/MyDrive/korpusblogspertiga.csv')\n",
        "dfblog.rename(columns={\"text\":\"teks\"},inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GRBinzhRAs_"
      },
      "source": [
        "dfgab=pd.read_csv('/content/drive/MyDrive/korpusblognewstweet.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNtvPjXBH3EY"
      },
      "source": [
        "dftwit = pd.read_csv('/content/drive/MyDrive/twitter_prosessed.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJQ2WLfjHRWr"
      },
      "source": [
        "dftwit2 = pd.read_csv('/content/drive/MyDrive/cstwitter_prosessed.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzk74fea1tsg"
      },
      "source": [
        "df1 = pd.read_csv(url0)\n",
        "df1=df1.drop(df1[df1['emosi'] == 'joy'].sample(frac=1).index)\n",
        "df1=df1.drop(df1[df1['emosi'] == 'sadness'].sample(frac=1).index)\n",
        "df1=df1.drop(df1[df1['emosi'] == 'anger'].sample(frac=1).index)\n",
        "df1=df1.drop(df1[df1['emosi'] == 'fear'].sample(frac=1).index)\n",
        "df1=df1.drop(df1[df1['emosi'] == 'disgust'].sample(frac=1).index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMa_pQzM4dQb"
      },
      "source": [
        "df2=pd.read_csv('https://raw.githubusercontent.com/alfinmaulani/skripsi/master/korpus2.txt', delimiter = \";\")\n",
        "df2.columns=['dok','tes']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlpBZNIA90g7"
      },
      "source": [
        "df3=pd.read_csv('https://raw.githubusercontent.com/alfinmaulani/skripsi/master/korpus3.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUFbo1WTSp2S"
      },
      "source": [
        "df4=pd.read_csv('https://raw.githubusercontent.com/alfinmaulani/skripsi/master/korpus4.tsv', delimiter = \"\t\")\n",
        "df4.columns=['dok','num','code']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTtcjTDCa4QQ"
      },
      "source": [
        "df5=pd.read_csv('https://raw.githubusercontent.com/alfinmaulani/skripsi/master/twitter_prosessed2.csv')#bad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zQ0bincqHri"
      },
      "source": [
        "dfwiki = pd.read_csv('/content/drive/MyDrive/idwiki_new_lower2.txt', delimiter = \"\\t\")\n",
        "dfwiki.columns = [\"arti\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1bl3-ku96wm"
      },
      "source": [
        "# df4 = pd.read_csv('/content/drive/MyDrive/idwiki_new_lower2.txt', delimiter = \"\\t\")\n",
        "# df4.columns = [\"arti\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EpWZexEyv1v"
      },
      "source": [
        "persiapan corpus tambahan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akKqMCydM_cp"
      },
      "source": [
        "final=[]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foRO9OiuRxUn"
      },
      "source": [
        "final.extend(dfgab.teks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE-0DNNCRvVg"
      },
      "source": [
        "final.extend(dfblog.teks)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7pNlgpBSvT3"
      },
      "source": [
        "final.extend(dftwit.tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLVsQkwIHUXI"
      },
      "source": [
        "final.extend(dftwit2.teks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-qhku9KYLvT"
      },
      "source": [
        "final.extend(dfwiki.arti)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhgrRcxoytWJ"
      },
      "source": [
        "final.extend(df1.dokumen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFpOfINNWwQp"
      },
      "source": [
        "final.extend(df2.dok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ui9LGKtytkd"
      },
      "source": [
        "final.extend(df3.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3ZfwA7j-Cvq"
      },
      "source": [
        "final.extend(df4.dok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVv4vqdIbMGv"
      },
      "source": [
        "final.extend(df5.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nurscmjE-Cf4"
      },
      "source": [
        "dfg = pd.DataFrame(final)\n",
        "dfg.columns=[\"dok\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Vnr7idZXyY"
      },
      "source": [
        "preputama : lower case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RypDx3ICZPoM"
      },
      "source": [
        "def lower(temp):\n",
        "  return temp.str.lower()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhpBZ6kQ9Wb5"
      },
      "source": [
        "df['dokumen']=lower(df['dokumen'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhbcH2FevErI"
      },
      "source": [
        "dfg['dok']=lower(dfg['dok'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b82j_2JPZaQ8"
      },
      "source": [
        "preputama : Pembersihan noise (over enter and space)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RQsSdV6Z6ZF"
      },
      "source": [
        "def bersih_noise(temp):\n",
        "  temp=temp.replace(' \\n', ' ', regex=True)\n",
        "  temp=temp.replace('   ', ' ', regex=True)\n",
        "  return temp.replace('  ', ' ', regex=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe0GqxmE9WP2"
      },
      "source": [
        "df=bersih_noise(df)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIur4tdzIBzl"
      },
      "source": [
        "dfg=bersih_noise(dfg)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KUKEZPEZdku"
      },
      "source": [
        "preptambah : expand contractions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvUkcyckt3jt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab032eb-4ffb-45b9-fd31-029c44364042"
      },
      "source": [
        "!pip install contractions\n",
        "import contractions\n",
        "def expand_word(temp):\n",
        "  expanded_words = []   \n",
        "  for word in temp:\n",
        "    expanded_words.append(contractions.fix(word))\n",
        "  return expanded_words"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.0.58-py2.py3-none-any.whl (8.0 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 41.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85446 sha256=42332ae22674773817afc4cee75d2f04bd7c7b4608d267d115bc89ab30457fa7\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.0 contractions-0.0.58 pyahocorasick-1.4.2 textsearch-0.0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5glvogu8t3dl"
      },
      "source": [
        "df.dokumen=expand_word(df.dokumen)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVjxLBLIIjXV"
      },
      "source": [
        "dfg.dok=expand_word(dfg.dok)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS8J8JjJamsx"
      },
      "source": [
        "preputama : cleansing punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3Hx4NpTbtrT"
      },
      "source": [
        "def clns_punc(temp):\n",
        "  return temp.str.replace(r'[^\\w\\s]+', '')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z_rN6_Famg-"
      },
      "source": [
        "df['dokumen'] = clns_punc(df['dokumen'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5TnuwyKqmyj"
      },
      "source": [
        "dfg['dok'] = clns_punc(dfg['dok'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3p4Wtl9TWVY"
      },
      "source": [
        "preputama : cleansing number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9OjkbaHDMU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052448cd-6ac9-4eae-bc18-7850a7afecbd"
      },
      "source": [
        "!pip install tweet-preprocessor\n",
        "import preprocessor as p\n",
        "p.set_options(p.OPT.NUMBER)\n",
        "def clns_numb(temp):\n",
        "  sementara=[]\n",
        "  for word in temp:\n",
        "    sementara.append(p.clean(word))\n",
        "  return sementara"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.7/dist-packages (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbDKUmvtDRjN"
      },
      "source": [
        "df.dokumen=clns_numb(df.dokumen)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmWovA8ADRby"
      },
      "source": [
        "dfg.dok=clns_numb(dfg.dok)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrfg5PlYaK_o"
      },
      "source": [
        "preptambah : remove stopword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol3lV82FbtgA",
        "outputId": "1ba459df-719a-4783-c3ac-8e1f410652fd"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "pat = r'\\b(?:{})\\b'.format('|'.join(stop))\n",
        "def remove_stopw(temp):\n",
        "  temp=temp.str.replace(pat, '')\n",
        "  return temp.str.replace(r'\\s+', ' ')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKuF-6uCZ9Y1"
      },
      "source": [
        "df['dokumen'] = remove_stopw(df['dokumen'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V77e41lhI5T7"
      },
      "source": [
        "dfg['dok'] = remove_stopw(dfg['dok'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnbrT-4daeEK"
      },
      "source": [
        "tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R5e1dYGdbYE"
      },
      "source": [
        "def token(temp):\n",
        "  return [word_tokenize(x) for x in temp]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpqeTa21Z9OS"
      },
      "source": [
        "df.dokumen=token(df.dokumen)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzBtjKLRJAQm"
      },
      "source": [
        "dfg.dok=token(dfg.dok)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrBmBYUFV5BP"
      },
      "source": [
        "preptambah : Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1ywmZGYZ9RJ"
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "def lemma(temp):\n",
        "  temp.apply(lambda x: [stemmer.stem(y) for y in x])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vonaeiobZ9Lh"
      },
      "source": [
        "lemma(df['dokumen'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-LWL8O_rEXB"
      },
      "source": [
        "lemma(dfg['dok'])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-NOlQnGbDUj"
      },
      "source": [
        "save df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk1V4HBPDHVw"
      },
      "source": [
        "df.to_csv(r'dataisear(preptambah).csv', index = False)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be5Oi1vVRVFX"
      },
      "source": [
        "dfg.to_csv(r'korpusblogspertiga(preptambah).csv', index = False)"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}